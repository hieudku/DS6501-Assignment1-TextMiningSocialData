labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name")
PlotA
teeth_dose <- ToothGrowth
teeth_dose
dotchart(x = teeth_dose$length, labels = NULL, groups
= teeth_dose$dose, pch = 16)
teeth_dose
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name")
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot(data = mtcars, aes (x = hp, y = mpg))
PlotA
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name")
PlotA
coord_flip()
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name")
PlotA
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name")
x1 <- 0
x2 <- 500
y1 <- 0
y2 <- 50
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA
x1 <- 0
x2 <- 5000
y1 <- 0
y2 <- 500
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2))
PlotA
x1 <- 0
x2 <- 500
y1 <- 0
y2 <- 50
PlotA <- ggplot( data = mtcars, aes(x = hp, y = mpg, color =
as.character(gear))) +
geom_line() +
labs(title = "plot_name"
, subtitle = "subtitle_name"
,
x = "xtab_name", y = "ytabname"
, caption = "cap_name"
,
color = "legend_name") +
xlim(c(x1,x2)) +
ylim(c(y1,y2)) +
coord_flip()
PlotA
PlotA
teeth_dose <- read.csv("./dataset/teeth_dose.csv")
getwd()
dir_path <- "C:\Users\hieu.cu_it.weltec\OneDrive - Whitireia and WelTec\Social-Data\Assignment1\DS6501-Assignment1-TextMiningSocialData"
dir_path <- "C:\\Users\\hieu.cu_it.weltec\\OneDrive - Whitireia and WelTec\\Social-Data\\Assignment1\\DS6501-Assignment1-TextMiningSocialData"
setwd(dir_path)
getwd()
dir_path <- "C:\\Users\\hieu.cu_it.weltec\\OneDrive - Whitireia and WelTec\\Social-Data\\Assignment1\\DS6501-Assignment1-TextMiningSocialData\\Social-Data-Mining"
setwd(dir_path)
getwd()
# Install packages into R Studio
install.packages("SnowballC")
install.packages("tm")
install.packages("syuzhet")
install.packages("wordcloud")
# Load libraries into R Studio
library(SnowballC)
library(tm)
library(syuzhet)
library(wordcloud)
tweets_Green.df <- read.csv("./Political Parties/NZGreens_tweets.csv")
tweets_National.df <- read.csv("./Political Parties/NZNationalParty_tweets.csv")
tweets_Labour.df <- read.csv("./Political Parties/nzlabour_tweets.csv")
# Display tweets
head(tweets_Green.df)
head(tweets_National.df)
head(tweets_Labour.df)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
tweets_Green.df2 <- tweets_Green.df$text
tweets_National.df2 <- tweets_National.df$text
tweets_Labour.df2 <- tweets_Labour.df$text
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Remove URLs from tweets for NZ Greens
tweets_Green.df2 <- gsub("http\\S+", "", tweets_Green.df2)
tweets_Green.df2 <- gsub("@.*","",tweets_Green.df2)
tweets_Green.df2 <- gsub("#.*","",tweets_Green.df2)
head(tweets_Green.df2)
tweets_National.df2 <- gsub("http.*","",tweets_National.df2)
tweets_Labour.df2 <- gsub("http.*","",tweets_Labour.df2)
head(tweets_National.df2)
# Display tweets
head(tweets_Green.df)
#############################################################
# Create Corpus from text files contained in Political folder
docs <- Corpus(DirSource("Political Parties"))
# View summary of the corpus
summary(docs)
docs[[1]]$content
#############################################################
# Create Corpus from text files contained in Political folder
docs <- Corpus(DirSource("NZGreens_tweets.csv"))
#############################################################
# Create Corpus from text files contained in Political folder
docs <- Corpus(DirSource("./NZGreens_tweets.csv"))
#############################################################
# Create Corpus from text files contained in Political folder
docs <- Corpus(DirSource("./NZGreens_tweets"))
#############################################################
# Create Corpus from text files contained in Political folder
docs <- Corpus(DirSource("Political Parties"))
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})
remvPattern <- content_transformer(function(x, pattern) {return (gsub(pattern, "", x))})
##########################
tweets_Green.df2 <- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})
tweets_Green.df2 <- content_transformer(function(x, pattern) {return (gsub(pattern, "", x))})
docs <- tm_map(docs, tweets_Green.df2, "-")
docs <- tm_map(docs, tweets_Green.df2, "http\\S+")
docs[[1]]$content
# Remove punctuation - replace punctuation marks with a space
docs <- tm_map(docs, removePunctuation)
#Transform to lower case (need to wrap in content_transformer)
docs <- tm_map(docs,content_transformer(tolower))
#Strip digits (std transformation - no need for content_transformer)
docs <- tm_map(docs, removeNumbers)
#remove stopwords using the standard list in tm
docs <- tm_map(docs, removeWords, stopwords("english"))
#Strip whitespace
docs <- tm_map(docs, stripWhitespace)
#######################
#Info about the docs
# View summary of the corpus
summary(docs)
# Get a list of documents in the corpus
names(docs)
# Access the content of a specific document
docs[[1]]$content
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
head(tweets_Green.df)
head(tweets_National.df)
head(tweets_Labour.df)
tweets_Green.df2 <- tweets_Green.df$text
tweets_National.df2 <- tweets_National.df$text
tweets_Labour.df2 <- tweets_Labour.df$text
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Access the content of a specific document
docs[[1]]$content
tweets_Green.df2 <- gsub("https?\\S+|www\\S+|@[A-Za-z0-9_]+|#[A-Za-z0-9_]+", "",tweets_Green.df2)
cleanse_tweets_Green.df2 <- gsub("https?\\S+|www\\S+|@[A-Za-z0-9_]+|#[A-Za-z0-9_]+", "",tweets_Green.df2)
cleanse_tweets_Green.df2 <- gsub("https?\\S+|www\\S+|@[A-Za-z0-9_]+|#[A-Za-z0-9_]+", "",tweets_Green.df2)
tweets_Green.df <- read.csv("./Political Parties/NZGreens_tweets.csv")
View(tweets_Green.df)
(tweets_Green.df)
head(tweets_Green.df$text)
tweets_Green.df2 <- tweets_Green.df$text
head(tweets_Green.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
getwd()
dir_path <- "C:\\Users\\hieu.cu_it.weltec\\OneDrive - Whitireia and WelTec\\Social-Data\\Assignment1\\DS6501-Assignment1-TextMiningSocialData\\Social-Data-Mining"
setwd(dir_path)
setwd(dir_path)
dir_path <- "C:\\Users\\hieu.cu_it.weltec\\OneDrive - Whitireia and WelTec\\Social-Data\\Assignment1\\DS6501-Assignment1-TextMiningSocialData\\Social-Data-Mining"
getwd()
install.packages("SnowballC")
install.packages("tm")
install.packages("syuzhet")
install.packages("wordcloud")
# Load libraries into R Studio
library(SnowballC)
library(tm)
library(syuzhet)
library(wordcloud)
tweets_Green.df <- read.csv("./Political Parties/NZGreens_tweets.csv")
tweets_National.df <- read.csv("./Political Parties/NZNationalParty_tweets.csv")
tweets_Labour.df <- read.csv("./Political Parties/nzlabour_tweets.csv")
head(tweets_Green.df)
head(tweets_National.df)
head(tweets_Labour.df)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Display clean text
head(tweets.df2)
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("http.*","",tweets_Green.df2)
tweets_National.df2 <- gsub("http.*","",tweets_National.df2)
# Clean tweets
clean_tweet <- function(tweet) {
tweet <- gsub("http\\S+|https\\S+|#\\S+|@\\S+|…", "", tweet)
tweet <- gsub("[^a-zA-Z\\s]", "", tweet)  # Remove non-alphabetic characters except spaces
return(tweet)
}
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
# Clean tweets
clean_tweet <- function(tweet) {
tweet <- gsub("http\\S+|https\\S+|#\\S+|@\\S+|…", "", tweet)
tweet <- gsub("[^a-zA-Z\\s]", "", tweet)  # Remove non-alphabetic characters except spaces
return(tweet)
}
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
getwd()
# Load libraries into R Studio
library(SnowballC)
library(tm)
library(syuzhet)
library(wordcloud)
# Install packages into R Studio
install.packages("SnowballC")
install.packages("tm")
install.packages("syuzhet")
install.packages("wordcloud")
install.packages("tm")
install.packages("tm")
install.packages("wordcloud")
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df2 <- gsub("https?://\\S+|www\\.[^\\s]+", "",tweets_Green.df2)
# Define the clean_tweet function
clean_tweet <- function(tweet) {
# Remove URLs
tweet <- gsub("https?://\\S+|www\\.[^\\s]+", "", tweet)
# Remove special characters
tweet <- gsub("[^a-zA-Z0-9' ]+", "", tweet)
return(tweet)
}
# Now you can use clean_tweet to clean your tweets
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
# Define the clean_tweet function
clean_tweet <- function(tweet) {
# Remove URLs
tweet <- gsub("https?://\\S+|www\\.[^\\s]+", "", tweet)
# Remove special characters
tweet <- gsub("[^a-zA-Z0-9' ]+", "", tweet)
return(tweet)
}
# Now you can use clean_tweet to clean your tweets
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
# Define the clean_tweet function
clean_tweet <- function(tweet) {
# Remove URLs
tweet <- gsub("https?://\\S+|www\\.[^\\s]+", "", tweet)
# Remove special characters
tweet <- gsub("[^[:alnum:]' ]", "", tweet)
return(tweet)
}
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
# Define the clean_tweet function
clean_tweet <- function(tweet) {
# Convert text to UTF-8 encoding
tweet <- iconv(tweet, "UTF-8", "UTF-8", sub = "byte")
# Remove URLs
tweet <- gsub("https?://\\S+|www\\.[^\\s]+", "", tweet)
# Remove special characters
tweet <- gsub("[^[:alnum:]' ]", "", tweet)
return(tweet)
}
tweets_Green.df$text <- sapply(tweets_Green.df$text, clean_tweet)
tweets_National.df$text <- sapply(tweets_National.df$text, clean_tweet)
tweets_Labour.df$text <- sapply(tweets_Labour.df$text, clean_tweet)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
tweets_Green.df$text <- sapply(tweets_Green.df2, clean_tweet)
tweets_National.df$text <- sapply(tweets_National.df2, clean_tweet)
tweets_Labour.df$text <- sapply(tweets_Labour.df2, clean_tweet)
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
tweets_Green.df2 <- sapply(tweets_Green.df2, clean_tweet)
tweets_National.df2 <- sapply(tweets_National.df2, clean_tweet)
tweets_Labour.df2 <- sapply(tweets_Labour.df2, clean_tweet)
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
head(tweets_Green.df$text)
head(tweets_National.df$text)
head(tweets_Labour.df$text)
# Use a 'find and replace' function to remove garbage from tweets
tweets_Green.df$text <- gsub("http.*","",tweets_Green.df$text)
head(tweets_Green.df2)
head(tweets_National.df2)
head(tweets_Labour.df2)
getwd()
