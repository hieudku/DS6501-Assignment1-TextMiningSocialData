# Load required Packages, but only if you need them.

# Execute the library commands first to see which command(s)generate an error.
# Un-comment the install.packages for those library commands that generate
# an error message. Remember to add the # symbol back again after installing
# any required packages to avoid installing them again in a future session.

# install.packages("SnowballC")
# install.packages("tm")
# install.packages("syuzhet")
# install.packages("wordcloud")

# Load libraries into R Studio
library(SnowballC)
library(tm)
library(syuzhet)
library(wordcloud)

####################################################################


tweets.df <- read.csv("TrumpTweets.csv")

# Display tweets
head(tweets.df)

# Display 'text' field of data frame
head(tweets.df$text)
tweets.df2 <- tweets.df$text

# Use a 'find and replace' function to remove garbage from tweets

tweets.df2 <- gsub("http.*","",tweets.df2)
# The '.* means it will remove all text to the right of the pattern
# found - http in the example above. This would clear the whole tweet
# if it begin with this pattern, so be careful.

tweets.df2 <- gsub("https.*","",tweets.df2)

# Remove everything shown between the square brackets - very useful
# Avoids striping the whole tweet, unlike '.*' option
tweets.df2 <- gsub("[\\]+","",tweets.df2)

tweets.df2 <- gsub("#.*","",tweets.df2)
# Display clean text
#head(tweets.df2)

tweets.df2 <- gsub("@.*","",tweets.df2) # Donald tweets
tweets.df2 <- gsub("â€¦","",tweets.df2)
#tweets.df2 <- gsub("@","",tweets.df2) # Airline tweets

# tweets.df2 <- gsub(".","",tweets.df2)

# Display clean text
head(tweets.df2)

# Convert data frame into a vector before performing sentiment analysis
word.df <- as.vector(tweets.df2)

# Perform sentiment analysis to score tweets on emotion
emotion.df <- get_nrc_sentiment(word.df)

# Combine tweets to sentiment scores
emotion.df2 <- cbind(tweets.df2, emotion.df) 

head(emotion.df2)

# Score tweets based on positive and negative sentiment
sent.value <- get_sentiment(word.df)
# sent.value <- get_sentiment(word.df, method = "bing") # Alternative

# Filter based on positive, negative and neutral tweets
positive.tweets <- word.df[sent.value > 0]

negative.tweets <- word.df[sent.value < 0]

neutral.tweets <- word.df[sent.value == 0]

# We can display each of the above using the head() command


# Count number of positive, negative and neutral tweets

pos <- length(positive.tweets)

neut <- length(neutral.tweets)

neg <- length(negative.tweets)

# Using the values in pos, neut and neg, we can plot a pie chart
# First combine the values and assign to a vector
x <- c(pos, neut, neg)

# Now define the labels to be used in pie chart 
labels <- c("Positive", "Negative", "Neutral")


# Finally, plot the chart
pie(x, labels, main = "Sentiment Analysis", col = rainbow(length(x)))


# Select the most positive sentiment (highest sent.value)

most.positive <- word.df[sent.value == max(sent.value)]

# Display tweet with most positive sentiment
most.positive

# Select the most negative sentiment (lowest sent.value)

most.negative <- word.df[sent.value <= min(sent.value)] 

# Display tweet with most negative sentiment
most.negative 

# We can also display a selection of neutral tweets
head(neutral.tweets)

# Create a corpus (collection of words) from our data frame of cleaned tweets
tweet_corpus <- Corpus(VectorSource(word.df))

# create term document matrix applying some transformations
tdm <- TermDocumentMatrix(tweet_corpus,
                          control = list(removePunctuation = TRUE, wordLengths=c(4, 20),
                                         stopwords = c("POTUS", "president", stopwords("english")),
                                         removeNumbers = TRUE, tolower = TRUE))


# define tdm as matrix so we can calculate word frequencies
tdm.matrix <- as.matrix(tdm)

# get word counts in decreasing order
word_freqs <- sort(rowSums(tdm.matrix), decreasing=TRUE) 

# create a data frame with words and their frequencies
dm <- data.frame(word=names(word_freqs), freq=word_freqs)

# plot wordcloud with words that appear at least 10 times
wordcloud(dm$word, dm$freq, min.freq = 10, 
          random.order=FALSE, colors=brewer.pal(8, "Dark2"))

